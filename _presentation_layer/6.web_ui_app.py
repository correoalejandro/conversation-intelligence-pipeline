# ğŸ“„ 4.v6.web_ui_app.py (CLICKABLE TABLE & SYNCHRONIZED VIEWER)
import joblib
from _data_layer.api import load_registry, load_artifact
from _data_layer.registry import find
from _data_layer.api import _backend   # â† loader oficial (json, joblib, etc.)

from _presentation_layer.web_renderer import (
    render_artifact_table,
    render_artifact_viewer,
    render_data_table,
    render_metadata,
    render_umap_plot
)
import pandas as pd
from pathlib import Path
import json
import plotly.express as px
import matplotlib.cm as cm
import matplotlib.colors as mcolors

import streamlit as st
from _data_layer.api import load_artifact
#from _data_layer.registry import find  # âœ… add this
# Sidebar navigation
st.sidebar.title("Navigation")

# ---------------------------------------------------------------------------
# Carga & fusiÃ³n de todos los technical_registry.json
# ---------------------------------------------------------------------------

def load_all_technical_registries(base_dir: str = "registries") -> pd.DataFrame:
    """
    Devuelve un DataFrame con TODOS los artefactos tÃ©cnicos encontrados
    en cualquier subcarpeta dentro de *base_dir*, sin importar si cada
    technical_registry.json es:
        â€¢ un dict por secciones (generator, embeddings, â€¦)   Ã³
        â€¢ una lista de artefactos ya â€œplanosâ€
    Siempre garantiza las columnas: stage, created_at, backend, data_ref, pipeline.
    """
    def _norm(art: dict, stage: str, pipeline: str, reg_defaults: dict | None = None) -> dict:
        """Homogeneiza campos para la UI."""
        reg_defaults = reg_defaults or {}
        art = art.copy()
        art["stage"]      = art.get("stage")      or stage or "unknown"
        art["pipeline"]   = pipeline
        art["created_at"] = (art.get("created_at")
                             or art.get("generated_at")
                             or reg_defaults.get("generated_at"))
        art["backend"]    = (art.get("backend")
                             or art.get("model")
                             or art.get("algorithm")
                             or art.get("type"))
        art["data_ref"] = art.get("data_ref") or art.get("id")
        return art

    artifacts: list[dict] = []
    base_path = Path(base_dir)

    if not base_path.exists():
        st.error(f"âŒÂ La carpeta '{base_dir}' no existe.")
        return pd.DataFrame()

    for tech_path in base_path.rglob("technical_registry.json"):
        try:
            reg = json.load(tech_path.open(encoding="utf-8"))
        except Exception as e:
            st.warning(f"âš ï¸Â No se pudo leer {tech_path}: {e}")
            continue

        pipeline = tech_path.parent.name  # ej. â€œpipeline_Aâ€

        # Caso 1: registry = dict por secciones
        if isinstance(reg, dict):
            for stage in ("generator", "preprocessing", "embeddings",
                          "clusters", "topics", "evaluation"):
                art = reg.get(stage)
                if art:
                    artifacts.append(_norm(art, stage, pipeline, reg))

            # Dict que trae una clave â€œartifactsâ€: [ â€¦ ]
            if isinstance(reg.get("artifacts"), list):
                for art in reg["artifacts"]:
                    artifacts.append(_norm(art, art.get("stage"), pipeline, reg))

        # Caso 2: registry = lista de artefactos â€œplanosâ€
        elif isinstance(reg, list):
            for art in reg:
                artifacts.append(_norm(art, art.get("stage"), pipeline))

        else:
            st.warning(f"âš ï¸Â Formato no reconocido en {tech_path}")

    # ---- DataFrame final ----
    df = pd.DataFrame(artifacts)
    for col in ["stage", "created_at", "backend", "data_ref", "pipeline"]:
        if col not in df.columns:
            df[col] = None
    return df

# -----------------------------------------------------------------
# ğŸ”„  Cargar bundle (.joblib) con heurÃ­sticas de nombres
# -----------------------------------------------------------------
DATA_FOLDER = Path("./data/experiments")   # ajusta si tu ruta cambia

def load_bundle_joblib(artifact: dict | None):
    """
    Busca un .joblib relacionado con *artifact* e intenta cargarlo.
    Devuelve el bundle o None.
    """
    if not artifact:
        return None

    # Candidatos de bÃºsqueda
    candidates: list[str] = []
    data_ref = str(artifact.get("data_ref", ""))
    digest   = str(artifact.get("hash", ""))
    stage    = str(artifact.get("stage", ""))

    if data_ref:
        candidates += [data_ref, data_ref.split("_")[0]]
    if digest:
        candidates.append(digest)
    if stage:
        candidates.append(stage)

    # Buscar coincidencias
    for pattern in candidates:
        for path in DATA_FOLDER.glob("*.joblib"):
            if pattern and pattern in path.stem:
                try:
                    return joblib.load(path)
                except Exception as e:
                    st.warning(f"âš ï¸Â Error al cargar {path.name}: {e}")
                    return None
    return None


# ğŸ“‚ Load registry once
artifact_df = load_all_technical_registries()

# ğŸ”„ Session state to track selected artifact
if "selected_artifact_id" not in st.session_state:
    st.session_state.selected_artifact_id = None

# âœ… nueva versiÃ³n (fila completa â†’ ID)
def on_artifact_select(row):
    st.session_state.selected_artifact_id = row["data_ref"]
    st.session_state.page = "Artifact Viewer"
# Page selector with remembered state
if "page" not in st.session_state:
    st.session_state.page = "Artifact Browser"

page = st.sidebar.radio(
    "Go to", [
        "Artifact Browser",
        "Artifact Viewer",
        "Conversation Viewer",
        "Conversation Timeline"  # âœ… new page
    ],
    index=[
        "Artifact Browser",
        "Artifact Viewer",
        "Conversation Viewer",
        "Conversation Timeline"
    ].index(st.session_state.page)
)



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”  Artifact Browser 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”§ columnas visibles en el Artifact Browser
display_cols = [
    c for c in ("stage", "created_at", "backend", "data_ref", "pipeline")
    if c in artifact_df.columns
]

if page == "Artifact Browser":
    st.title("ğŸ“š Artifact Browser")
    render_artifact_table(
        artifact_df[display_cols],
        on_select_callback=on_artifact_select   # clic en fila â†’ viewer
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”  Artifact Viewer  (con vistaâ€‘proyector)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "Artifact Viewer":
    st.title("ğŸ” Artifact Viewer")

    # 1ï¸âƒ£ Recuperar el ID seleccionado
    artifact_id = st.session_state.get("selected_artifact_id")
    if not artifact_id:
        st.info("Selecciona un artefacto desde *Artifact Browser*.")
        st.stop()

    # 2ï¸âƒ£ Mostrar detalles del registro
    sel = artifact_df[artifact_df["data_ref"] == artifact_id]
    if sel.empty:
        st.error(f"Artefacto '{artifact_id}' no encontrado en los registries.")
        st.stop()
    artifact_dict = sel.iloc[0].dropna().to_dict()
    st.subheader("ğŸ“„ Registro del artefacto")
    st.json(artifact_dict, expanded=True)

    # 3ï¸âƒ£ Cargar el .joblib correcto
    st.markdown("## ğŸ§  Artifact Projection")
    from pathlib import Path
    import joblib

    DATA_FOLDER = Path("data/experiments")
    raw_ref = artifact_dict["data_ref"]
    path = Path(raw_ref)

    # Si data_ref no contiene â€œ.joblibâ€ o el archivo no existe, buscamos en data/experiments
    if not (raw_ref.endswith(".joblib") and path.exists()):
        matches = list(DATA_FOLDER.glob(f"*{artifact_id}*.joblib"))
        if matches:
            path = matches[0]
        else:
            st.warning(f"âš ï¸ No se encontrÃ³ ningÃºn .joblib en '{DATA_FOLDER}' que contenga '{artifact_id}'.")
            df = None

    try:
        if path and path.exists():
            bundle = joblib.load(path)
            df = bundle.get("df")
        else:
            df = None
    except Exception as e:
        st.warning(f"âš ï¸ Error cargando {path.name}: {e}")
        df = None



    ##########################################
    # 4ï¸âƒ£ Scatter interactivo con Plotly (mejorado)
    
    #---------------------------------------# 
    
    
    # Prepara df_copy con etiquetas legibles
    if df is None:
        st.warning("âš ï¸ No hay DataFrame proyectable para este artefacto.")
        st.stop()
    df_copy = df.copy()
    df_copy["cluster"] = pd.to_numeric(df_copy["cluster"], errors="coerce").fillna(-1).astype(int)
    df_copy["cluster_label"] = df_copy["cluster"].apply(
        lambda c: "Outlier" if c == -1 else f"Cluster {c:03d}"
    )

    # Orden y lista de clÃºsteres
    unique_clusters = sorted(set(df_copy["cluster"]))
    clusters_no_outlier = [c for c in unique_clusters if c != -1]
    ordered_labels = ["Outlier"] + [f"Cluster {c:03d}" for c in clusters_no_outlier]

    # 1. Generar colores HSV equiespaciados para los no-outliers
    import matplotlib.cm as cm
    import matplotlib.colors as mcolors

    n = len(clusters_no_outlier)
    hsv_cmap = cm.hsv
    hsv_colors = [mcolors.to_hex(hsv_cmap(i / max(n, 1))) for i in range(n)]

    color_map = {"Outlier": "#CCCCCC"}
    for idx, c in enumerate(clusters_no_outlier):
        color_map[f"Cluster {c:03d}"] = hsv_colors[idx]


    # 2. Configurar sÃ­mbolos si no hay demasiados clÃºsteres
    symbol_args = {}
    if n <= 12:
        symbol_args = {
            "symbol": "cluster_label",
            "symbol_sequence": ['circle','square','diamond','cross','x','triangle-up','triangle-down']
        }  # :contentReference[oaicite:3]{index=3}

    # 3. Crear scatter
    fig = px.scatter(
        df_copy,
        x="umap_x",
        y="umap_y",
        color="cluster_label",
        color_discrete_map=color_map,
        category_orders={"cluster_label": ordered_labels},
        hover_name="conversation_id",
        render_mode="webgl",
        **symbol_args
    )

    # 4. AÃ±adir botones para seleccionar/deseleccionar
    fig.update_layout(
        updatemenus=[{
            "type": "buttons",
            "direction": "right",
            "x": 1.1,
            "y": 1.15,
            "showactive": False,
            "buttons": [
                {
                    "label": "Deseleccionar todos",
                    "method": "update",
                    "args": [{"visible": ["legendonly"] * len(fig.data)}, {}]
                },
                {
                    "label": "Seleccionar todos",
                    "method": "update",
                    "args": [{"visible": [True] * len(fig.data)}, {}]
                }
            ]
        }],
        legend=dict(itemclick="toggle", itemdoubleclick="toggleothers"),
        template="plotly_white",
        height=600,
        title="ğŸŒŒ UMAP Interactive Scatter Plot"
    )

    # 5. Renderizar en Streamlit
    st.plotly_chart(fig, use_container_width=True)



# ğŸ—£ Conversation Viewer (independent of artifacts)


elif page == "Conversation Viewer":
    st.title("ğŸ—£ Global Conversation Viewer")

    # Combine all generator batches
    generator_artifacts = find(stage="generator")
    dfs_all = []
    for art in generator_artifacts:
        df, meta = load_artifact(art["id"])
        if "conversation_id" in df.columns:
            dfs_all.append(df)
        else:
            st.warning(f"âš  Skipping artifact {meta['id']} (no 'conversation_id' column)")
    if not dfs_all:
        st.error("âŒ No generator artifacts with 'conversation_id' found.")
    else:
        df_all = pd.concat(dfs_all, ignore_index=True)

        # Also try merging cleaned text if available
        clean_artifacts = find(stage="preprocess:cleaned_json")
        dfs_clean = []
        for art in clean_artifacts:
            df_clean, _ = load_artifact(art["id"])
            if "conversation_id" in df_clean.columns:
                dfs_clean.append(df_clean)
        df_clean_all = pd.concat(dfs_clean, ignore_index=True) if dfs_clean else None

        st.markdown(f"ğŸ“– Loaded {len(df_all)} conversations from all batches.")

        # ğŸ”½ Dropdown for conversation_id
        conversation_ids = sorted(df_all["conversation_id"].unique())
        selected_id = st.selectbox(
            "ğŸ” Select a conversation_id:",
            conversation_ids,
            help="Pick a conversation ID to view its details"
        )

        # Show results from generator data
        matches = df_all[df_all["conversation_id"] == selected_id]
        st.success(f"âœ… Found {len(matches)} conversation(s) in generator data.")
        st.dataframe(matches)

        # Show results from cleaned text if available
        if df_clean_all is not None:
            clean_matches = df_clean_all[df_clean_all["conversation_id"] == selected_id]
            if not clean_matches.empty:
                st.info(f"âœ¨ Found {len(clean_matches)} cleaned version(s).")
                st.dataframe(clean_matches)
            else:
                st.warning("âš  No cleaned version found for this conversation.")

        st.markdown("---")
        st.caption("This viewer works independently of artifacts.")




# ğŸ“ˆ Conversation Timeline Viewer
elif page == "Conversation Timeline":
    st.title("ğŸ“ˆ Conversation Timeline")

    # Load all generator batches
    generator_artifacts = find(stage="generator")
    dfs_all = []
    for art in generator_artifacts:
        df, meta = load_artifact(art["id"])
        if "conversation_id" in df.columns:
            dfs_all.append(df)
        else:
            st.warning(f"âš  Skipping artifact {meta['id']} (no 'conversation_id' column)")

    if not dfs_all:
        st.error("âŒ No generator artifacts with 'conversation_id' found.")
    else:
        df_all = pd.concat(dfs_all, ignore_index=True)

        # ğŸ”½ Dropdown for conversation_id
        conversation_ids = sorted(df_all["conversation_id"].unique())
        selected_id = st.selectbox(
            "ğŸ” Select a conversation_id to explore:",
            conversation_ids,
            help="Pick a conversation to view its timeline"
        )

        # Get the selected conversation
        selected_conv = df_all[df_all["conversation_id"] == selected_id]
        if selected_conv.empty:
            st.error("âŒ Could not find conversation.")
        else:
            st.markdown(f"ğŸ“– **Conversation ID:** `{selected_id}`")

            # Try extracting message-level timestamps
            timestamps = []
            if "messages" in selected_conv.columns:
                messages = selected_conv.iloc[0]["messages"]
                if isinstance(messages, list) and "timestamp" in messages[0]:
                    timestamps = [msg["timestamp"] for msg in messages if "timestamp" in msg]

            if timestamps:
                st.success(f"âœ… Found {len(timestamps)} message timestamps.")
                ts_df = pd.DataFrame({
                    "Timestamp": pd.to_datetime(timestamps),
                    "Message #": range(1, len(timestamps) + 1)
                })

                # ğŸªŸ Side-by-side collapsible panels
                col1, col2 = st.columns(2)

                with col1:
                    with st.expander("ğŸ“‹ Message Timestamps Table", expanded=True):
                        st.dataframe(ts_df, use_container_width=True)

                with col2:
                    with st.expander("ğŸ“ˆ Timeline Plot", expanded=True):
                        st.line_chart(ts_df.set_index("Timestamp")["Message #"])
            else:
                st.warning("âš  No message-level timestamps found in this conversation.")

    st.title("ğŸ—£ Global Conversation Viewer")

    # Combine all generator batches
    generator_artifacts = find(stage="generator")
    dfs_all = []
    for art in generator_artifacts:
        df, meta = load_artifact(art["id"])
        if "conversation_id" in df.columns:
            dfs_all.append(df)
        else:
            st.warning(f"âš  Skipping artifact {meta['id']} (no 'conversation_id' column)")
    if not dfs_all:
        st.error("âŒ No generator artifacts with 'conversation_id' found.")
    else:
        df_all = pd.concat(dfs_all, ignore_index=True)

        # Also try merging cleaned text if available
        clean_artifacts = find(stage="preprocess:cleaned_json")
        dfs_clean = []
        for art in clean_artifacts:
            df_clean, _ = load_artifact(art["id"])
            if "conversation_id" in df_clean.columns:
                dfs_clean.append(df_clean)
        df_clean_all = pd.concat(dfs_clean, ignore_index=True) if dfs_clean else None

        st.markdown(f"ğŸ“– Loaded {len(df_all)} conversations from all batches.")

        # ğŸ”½ Dropdown for conversation_id
        conversation_ids = sorted(df_all["conversation_id"].unique())
        selected_id = st.selectbox(
            "ğŸ” Select a conversation_id:",
            conversation_ids,
            help="Pick a conversation ID to view its details"
        )

        # Show results from generator data
        matches = df_all[df_all["conversation_id"] == selected_id]
        st.success(f"âœ… Found {len(matches)} conversation(s) in generator data.")
        st.dataframe(matches)

        # Show results from cleaned text if available
        if df_clean_all is not None:
            clean_matches = df_clean_all[df_clean_all["conversation_id"] == selected_id]
            if not clean_matches.empty:
                st.info(f"âœ¨ Found {len(clean_matches)} cleaned version(s).")
                st.dataframe(clean_matches)
            else:
                st.warning("âš  No cleaned version found for this conversation.")

        st.markdown("---")
        st.caption("This viewer works independently of artifacts.")


    st.title("ğŸ“ˆ Conversation Timeline")

    # Load all generator batches
    generator_artifacts = find(stage="generator")
    dfs_all = []
    for art in generator_artifacts:
        df, meta = load_artifact(art["id"])
        if "conversation_id" in df.columns:
            dfs_all.append(df)
        else:
            st.warning(f"âš  Skipping artifact {meta['id']} (no 'conversation_id' column)")

    if not dfs_all:
        st.error("âŒ No generator artifacts with 'conversation_id' found.")
    else:
        df_all = pd.concat(dfs_all, ignore_index=True)

        # ğŸ”½ Dropdown for conversation_id
        conversation_ids = sorted(df_all["conversation_id"].unique())
        selected_id = st.selectbox(
            "ğŸ” Select a conversation_id to explore:",
            conversation_ids,
            help="Pick a conversation to view its timeline"
        )

        # Get the selected conversation
        selected_conv = df_all[df_all["conversation_id"] == selected_id]
        if selected_conv.empty:
            st.error("âŒ Could not find conversation.")
        else:
            st.markdown(f"ğŸ“– **Conversation ID:** `{selected_id}`")

            # Try extracting message-level timestamps
            timestamps = []
            if "messages" in selected_conv.columns:
                messages = selected_conv.iloc[0]["messages"]
                if isinstance(messages, list) and "timestamp" in messages[0]:
                    timestamps = [msg["timestamp"] for msg in messages if "timestamp" in msg]

            if timestamps:
                st.success(f"âœ… Found {len(timestamps)} message timestamps.")
                ts_df = pd.DataFrame({
                    "Timestamp": pd.to_datetime(timestamps),
                    "Message #": range(1, len(timestamps) + 1)
                })

                # ğŸªŸ Side-by-side collapsible panels
                col1, col2 = st.columns(2)

                with col1:
                    with st.expander("ğŸ“‹ Message Timestamps Table", expanded=True):
                        st.dataframe(ts_df, use_container_width=True)

                with col2:
                    with st.expander("ğŸ“ˆ Timeline Plot", expanded=True):
                        st.line_chart(ts_df.set_index("Timestamp")["Message #"])
            else:
                st.warning("âš  No message-level timestamps found in this conversation.")

    st.title("ğŸ“ˆ Conversation Timeline")

    # Load all generator batches
    generator_artifacts = find(stage="generator")
    dfs_all = []
    for art in generator_artifacts:
        df, meta = load_artifact(art["id"])
        if "conversation_id" in df.columns:
            dfs_all.append(df)
        else:
            st.warning(f"âš  Skipping artifact {meta['id']} (no 'conversation_id' column)")

    if not dfs_all:
        st.error("âŒ No generator artifacts with 'conversation_id' found.")
    else:
        df_all = pd.concat(dfs_all, ignore_index=True)

        # ğŸ”½ Dropdown for conversation_id
        conversation_ids = sorted(df_all["conversation_id"].unique())
        selected_id = st.selectbox(
            "ğŸ” Select a conversation_id to plot:",
            conversation_ids,
            help="Pick a conversation to explore its timeline"
        )

        # Get the selected conversation
        selected_conv = df_all[df_all["conversation_id"] == selected_id]
        if selected_conv.empty:
            st.error("âŒ Could not find conversation.")
        else:
            st.markdown(f"ğŸ“– **Conversation ID:** `{selected_id}`")

            # Try extracting message-level timestamps
            timestamps = []
            if "messages" in selected_conv.columns:
                messages = selected_conv.iloc[0]["messages"]
                if isinstance(messages, list) and "timestamp" in messages[0]:
                    timestamps = [msg["timestamp"] for msg in messages if "timestamp" in msg]

            # Show timestamps table
            if timestamps:
                st.success(f"âœ… Found {len(timestamps)} message timestamps.")
                ts_df = pd.DataFrame({
                    "Timestamp": pd.to_datetime(timestamps),
                    "Message #": range(1, len(timestamps) + 1)
                })
                st.dataframe(ts_df)

                # Plot time series
                st.line_chart(ts_df.set_index("Timestamp")["Message #"])
            else:
                st.warning("âš  No message-level timestamps found in this conversation.")

            # Optional: check for conversation-level timestamp
            if "timestamp" in selected_conv.columns:
                conv_ts = selected_conv.iloc[0]["timestamp"]
                st.info(f"ğŸ“… Conversation-level timestamp: `{conv_ts}`")